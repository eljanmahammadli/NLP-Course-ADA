{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        translated = translator.translate(text, src='en', dest='az')\n",
    "        return translated.text\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add whitespace to the end of the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/65g9k4kd4_j8k3x277xdkd500000gn/T/ipykernel_1995/1520998717.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('sentiment').apply(lambda x: x.sample(1000)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/IMDB Dataset.csv')\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "df = df.groupby('sentiment').apply(lambda x: x.sample(1000)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    1000\n",
       "1    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 108/2000 [03:31<1:27:33,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 143/2000 [04:55<1:34:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 164/2000 [05:39<43:54,  1.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 245/2000 [08:22<1:21:59,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 276/2000 [09:32<1:33:44,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 360/2000 [12:06<34:06,  1.25s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 749/2000 [24:45<31:25,  1.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 867/2000 [28:37<30:48,  1.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1104/2000 [36:31<25:55,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1136/2000 [37:44<46:39,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1259/2000 [41:55<40:26,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1329/2000 [44:24<15:08,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1501/2000 [50:36<11:32,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1550/2000 [52:03<09:44,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1595/2000 [53:32<09:23,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1609/2000 [53:56<09:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1655/2000 [55:31<09:57,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1689/2000 [56:34<07:29,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1736/2000 [58:08<07:10,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1739/2000 [58:17<12:20,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1753/2000 [58:43<05:36,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1803/2000 [1:00:14<04:10,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1860/2000 [1:02:06<06:42,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1941/2000 [1:04:50<01:36,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:06:49<00:00,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "df['review_az'] = df['review'].progress_apply(translate_text)\n",
    "df.to_csv('../data/IMDB Dataset_az.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented this movie because it sounded pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bu filmi icarəyə götürdüm, çünki olduqca maraq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Ghost Son\" is Lamberto Bava's best film and, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Ghost oğlu\" Lamberto Bava'nın ən yaxşı filmi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film's basic premise is a political carto...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bu filmin əsas binası bir siyasi cizgi filmidi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disney has yet to meet a movie it couldn't mak...</td>\n",
       "      <td>0</td>\n",
       "      <td>Disney hələ ən azı iki ardıcıllıqla edə bilməd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This film is just plain horrible. John Ritter ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bu film sadəcə dəhşətlidir.John Ritter, pratt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>The magnitude of the Stalingrad tragedy is con...</td>\n",
       "      <td>1</td>\n",
       "      <td>Stalinqrad faciəsinin böyüklüyü filmin sonunda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I think that this movie was reasonbaly good. I...</td>\n",
       "      <td>1</td>\n",
       "      <td>Düşünürəm ki, bu film əsaslığa yaxşı idi.İndi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Every high praise word fell way short before t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hər yüksək tərif sözü bu filmin hündürlüyündən...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>\"Foxes\" is a serious look at the consequences ...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Tülkülər\" 1980-ci illərdə çox sürətlə böyüdün...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Niagara, Niagara is a stunning and heartbreaki...</td>\n",
       "      <td>1</td>\n",
       "      <td>Niagara, Niagara, Seth və Marcy iki kənar adam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment  \\\n",
       "0     I rented this movie because it sounded pretty ...          0   \n",
       "1     \"Ghost Son\" is Lamberto Bava's best film and, ...          0   \n",
       "2     This film's basic premise is a political carto...          0   \n",
       "3     Disney has yet to meet a movie it couldn't mak...          0   \n",
       "4     This film is just plain horrible. John Ritter ...          0   \n",
       "...                                                 ...        ...   \n",
       "1995  The magnitude of the Stalingrad tragedy is con...          1   \n",
       "1996  I think that this movie was reasonbaly good. I...          1   \n",
       "1997  Every high praise word fell way short before t...          1   \n",
       "1998  \"Foxes\" is a serious look at the consequences ...          1   \n",
       "1999  Niagara, Niagara is a stunning and heartbreaki...          1   \n",
       "\n",
       "                                              review_az  \n",
       "0     Bu filmi icarəyə götürdüm, çünki olduqca maraq...  \n",
       "1     \"Ghost oğlu\" Lamberto Bava'nın ən yaxşı filmi ...  \n",
       "2     Bu filmin əsas binası bir siyasi cizgi filmidi...  \n",
       "3     Disney hələ ən azı iki ardıcıllıqla edə bilməd...  \n",
       "4     Bu film sadəcə dəhşətlidir.John Ritter, pratt ...  \n",
       "...                                                 ...  \n",
       "1995  Stalinqrad faciəsinin böyüklüyü filmin sonunda...  \n",
       "1996  Düşünürəm ki, bu film əsaslığa yaxşı idi.İndi ...  \n",
       "1997  Hər yüksək tərif sözü bu filmin hündürlüyündən...  \n",
       "1998  \"Tülkülər\" 1980-ci illərdə çox sürətlə böyüdün...  \n",
       "1999  Niagara, Niagara, Seth və Marcy iki kənar adam...  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/IMDB Dataset_az.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_az</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bu filmi icarəyə götürdüm, çünki olduqca maraq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Ghost oğlu\" Lamberto Bava'nın ən yaxşı filmi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu filmin əsas binası bir siyasi cizgi filmidi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disney hələ ən azı iki ardıcıllıqla edə bilməd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bu film sadəcə dəhşətlidir.John Ritter, pratt ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Stalinqrad faciəsinin böyüklüyü filmin sonunda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Düşünürəm ki, bu film əsaslığa yaxşı idi.İndi ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Hər yüksək tərif sözü bu filmin hündürlüyündən...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>\"Tülkülər\" 1980-ci illərdə çox sürətlə böyüdün...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Niagara, Niagara, Seth və Marcy iki kənar adam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_az  sentiment\n",
       "0     Bu filmi icarəyə götürdüm, çünki olduqca maraq...          0\n",
       "1     \"Ghost oğlu\" Lamberto Bava'nın ən yaxşı filmi ...          0\n",
       "2     Bu filmin əsas binası bir siyasi cizgi filmidi...          0\n",
       "3     Disney hələ ən azı iki ardıcıllıqla edə bilməd...          0\n",
       "4     Bu film sadəcə dəhşətlidir.John Ritter, pratt ...          0\n",
       "...                                                 ...        ...\n",
       "1995  Stalinqrad faciəsinin böyüklüyü filmin sonunda...          1\n",
       "1996  Düşünürəm ki, bu film əsaslığa yaxşı idi.İndi ...          1\n",
       "1997  Hər yüksək tərif sözü bu filmin hündürlüyündən...          1\n",
       "1998  \"Tülkülər\" 1980-ci illərdə çox sürətlə böyüdün...          1\n",
       "1999  Niagara, Niagara, Seth və Marcy iki kənar adam...          1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['review_az', 'sentiment']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/65g9k4kd4_j8k3x277xdkd500000gn/T/ipykernel_4557/3399753417.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'review_az': 'text'}, inplace=True)\n",
      "/var/folders/ls/65g9k4kd4_j8k3x277xdkd500000gn/T/ipykernel_4557/3399753417.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'sentiment': 'label'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'review_az': 'text'}, inplace=True)\n",
    "df.rename(columns={'sentiment': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bu filmi icarəyə götürdüm, çünki olduqca maraq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Ghost oğlu\" Lamberto Bava'nın ən yaxşı filmi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu filmin əsas binası bir siyasi cizgi filmidi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disney hələ ən azı iki ardıcıllıqla edə bilməd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bu film sadəcə dəhşətlidir.John Ritter, pratt ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Stalinqrad faciəsinin böyüklüyü filmin sonunda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Düşünürəm ki, bu film əsaslığa yaxşı idi.İndi ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Hər yüksək tərif sözü bu filmin hündürlüyündən...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>\"Tülkülər\" 1980-ci illərdə çox sürətlə böyüdün...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Niagara, Niagara, Seth və Marcy iki kənar adam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Bu filmi icarəyə götürdüm, çünki olduqca maraq...      0\n",
       "1     \"Ghost oğlu\" Lamberto Bava'nın ən yaxşı filmi ...      0\n",
       "2     Bu filmin əsas binası bir siyasi cizgi filmidi...      0\n",
       "3     Disney hələ ən azı iki ardıcıllıqla edə bilməd...      0\n",
       "4     Bu film sadəcə dəhşətlidir.John Ritter, pratt ...      0\n",
       "...                                                 ...    ...\n",
       "1995  Stalinqrad faciəsinin böyüklüyü filmin sonunda...      1\n",
       "1996  Düşünürəm ki, bu film əsaslığa yaxşı idi.İndi ...      1\n",
       "1997  Hər yüksək tərif sözü bu filmin hündürlüyündən...      1\n",
       "1998  \"Tülkülər\" 1980-ci illərdə çox sürətlə böyüdün...      1\n",
       "1999  Niagara, Niagara, Seth və Marcy iki kənar adam...      1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/65g9k4kd4_j8k3x277xdkd500000gn/T/ipykernel_4557/920181123.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: \". \".join(x.split(\".\")))\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x: \". \".join(x.split(\".\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7833333333333333\n",
      "F1 Score: 0.7670250896057348\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       302\n",
      "           1       0.82      0.72      0.77       298\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.79      0.78      0.78       600\n",
      "weighted avg       0.79      0.78      0.78       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "# Suppose df is your DataFrame with 'text' and 'label' columns\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer() # You can also use CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Define your target variable\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"F1 Score:\", f1_score(y_test, predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'Film çox yaxşı idi. Çox xoşuma gəldi.'\n",
    "text2 = 'Film çox pis idi. Çox xoşuma gəlmədi.'\n",
    "text3 = 'Indiye qeder izlediyim en möhtəşəm film idi.'\n",
    "text4 = 'Yusif çox pis adam idi. Çox xoşuma gəlmədi.'\n",
    "nb.predict(vectorizer.transform([text1, text2, text3, text4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probs = defaultdict(float)\n",
    "        self.word_cond_probs = defaultdict(lambda: defaultdict(float))\n",
    "        self.vocab = set()\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Calculate class probabilities\n",
    "        class_counts = y_train.value_counts().to_dict()\n",
    "        total_docs = len(y_train)\n",
    "        for c in class_counts:\n",
    "            self.class_probs[c] = np.log(class_counts[c] / total_docs)\n",
    "\n",
    "        # Calculate conditional probabilities for each word given the class\n",
    "        word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        word_totals = defaultdict(int)\n",
    "        for text, c in zip(X_train, y_train):\n",
    "            for word in text.split():\n",
    "                self.vocab.add(word)\n",
    "                word_counts[c][word] += 1\n",
    "                word_totals[c] += 1\n",
    "\n",
    "        for c in class_counts:\n",
    "            for word in self.vocab:\n",
    "                self.word_cond_probs[c][word] = np.log(\n",
    "                    (word_counts[c][word] + 1) / (word_totals[c] + len(self.vocab))\n",
    "                )\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for text in X_test:\n",
    "            class_scores = {}\n",
    "            for c in self.class_probs:\n",
    "                score = self.class_probs[c]\n",
    "                for word in text.split():\n",
    "                    if word in self.vocab:\n",
    "                        score += self.word_cond_probs[c][word]\n",
    "                class_scores[c] = score\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        return predictions\n",
    "\n",
    "# Vectorize the text data manually or use the text as is for our simple implementation\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize, train, and predict using our Naive Bayes classifier\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer() # You can also use CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Define your target variable\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polygraf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
