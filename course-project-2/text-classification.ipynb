{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        translated = translator.translate(text, src='en', dest='az')\n",
    "        return translated.text\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da başlıqdakı sistas.Qisas və bling bling axtarır.Da Hood istisna olmaqla, 1800-cü illərin sonlarında vəhşi bir qərb şəhəridir.Böyüyəndə bu kimi qərbləri xatırlamıram.Randolph Skott nə dedi?Lil 'Kim'i görsə, \"Yaxşı,\" Deyə bilərmi? Mən onu görmək üçün buna görə də buna tabe olduğumu etiraf etməliyəm. Çılpaq midmallar və aşağı kəsilmiş bluzlar adi kovboy çiyninin ştapeli deyil, lakin bunlar inəkqollardır,və onlar yaxşıdır.Wayne kiməsə, \"Dawg\" adlandırırsan?Bu r reytinqi, amma bu hərəkətdə Lil 'Kim olsa, onu görmək üçün DVD-ni satın alacağımda şübhə edirəm.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/eljan/Documents/NLP/NLP-Course-ADA/data/IMDB Dataset_az.csv')\n",
    "print(df.sample(1).iloc[0]['review_az'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add whitespace to the end of the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/65g9k4kd4_j8k3x277xdkd500000gn/T/ipykernel_7552/1520998717.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('sentiment').apply(lambda x: x.sample(1000)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/IMDB Dataset.csv')\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "df = df.groupby('sentiment').apply(lambda x: x.sample(1000)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    1000\n",
       "1    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [00:04<45:05,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2000 [00:14<1:13:18,  2.21s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "df['review_az'] = df['review'].progress_apply(translate_text)\n",
    "df.to_csv('../data/IMDB Dataset_az.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented this movie because it sounded pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bu filmi icarəyə götürdüm, çünki olduqca maraq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Ghost Son\" is Lamberto Bava's best film and, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Ghost oğlu\" Lamberto Bava'nın ən yaxşı filmi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film's basic premise is a political carto...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bu filmin əsas binası bir siyasi cizgi filmidi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disney has yet to meet a movie it couldn't mak...</td>\n",
       "      <td>0</td>\n",
       "      <td>Disney hələ ən azı iki ardıcıllıqla edə bilməd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This film is just plain horrible. John Ritter ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bu film sadəcə dəhşətlidir.John Ritter, pratt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>The magnitude of the Stalingrad tragedy is con...</td>\n",
       "      <td>1</td>\n",
       "      <td>Stalinqrad faciəsinin böyüklüyü filmin sonunda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I think that this movie was reasonbaly good. I...</td>\n",
       "      <td>1</td>\n",
       "      <td>Düşünürəm ki, bu film əsaslığa yaxşı idi.İndi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Every high praise word fell way short before t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hər yüksək tərif sözü bu filmin hündürlüyündən...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>\"Foxes\" is a serious look at the consequences ...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Tülkülər\" 1980-ci illərdə çox sürətlə böyüdün...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Niagara, Niagara is a stunning and heartbreaki...</td>\n",
       "      <td>1</td>\n",
       "      <td>Niagara, Niagara, Seth və Marcy iki kənar adam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment  \\\n",
       "0     I rented this movie because it sounded pretty ...          0   \n",
       "1     \"Ghost Son\" is Lamberto Bava's best film and, ...          0   \n",
       "2     This film's basic premise is a political carto...          0   \n",
       "3     Disney has yet to meet a movie it couldn't mak...          0   \n",
       "4     This film is just plain horrible. John Ritter ...          0   \n",
       "...                                                 ...        ...   \n",
       "1995  The magnitude of the Stalingrad tragedy is con...          1   \n",
       "1996  I think that this movie was reasonbaly good. I...          1   \n",
       "1997  Every high praise word fell way short before t...          1   \n",
       "1998  \"Foxes\" is a serious look at the consequences ...          1   \n",
       "1999  Niagara, Niagara is a stunning and heartbreaki...          1   \n",
       "\n",
       "                                              review_az  \n",
       "0     Bu filmi icarəyə götürdüm, çünki olduqca maraq...  \n",
       "1     \"Ghost oğlu\" Lamberto Bava'nın ən yaxşı filmi ...  \n",
       "2     Bu filmin əsas binası bir siyasi cizgi filmidi...  \n",
       "3     Disney hələ ən azı iki ardıcıllıqla edə bilməd...  \n",
       "4     Bu film sadəcə dəhşətlidir.John Ritter, pratt ...  \n",
       "...                                                 ...  \n",
       "1995  Stalinqrad faciəsinin böyüklüyü filmin sonunda...  \n",
       "1996  Düşünürəm ki, bu film əsaslığa yaxşı idi.İndi ...  \n",
       "1997  Hər yüksək tərif sözü bu filmin hündürlüyündən...  \n",
       "1998  \"Tülkülər\" 1980-ci illərdə çox sürətlə böyüdün...  \n",
       "1999  Niagara, Niagara, Seth və Marcy iki kənar adam...  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('../data/IMDB Dataset_az.csv')\n",
    "df = df[['review_az', 'sentiment']]\n",
    "df.rename(columns={'review_az': 'text'}, inplace=True)\n",
    "df.rename(columns={'sentiment': 'label'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def split_sentences(text):\n",
    "    pattern = r'(?<=[.!?])\\s*'\n",
    "    sentences = re.split(pattern, text)\n",
    "    sentences_with_whitespace = ' '.join(sentences)\n",
    "    return sentences_with_whitespace\n",
    "\n",
    "df['text'] = df['text'].apply(split_sentences)\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "F1 Score: 0.7582417582417582\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.80       199\n",
      "           1       0.85      0.69      0.76       201\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.79      0.78      0.78       400\n",
      "weighted avg       0.79      0.78      0.78       400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[174  25]\n",
      " [ 63 138]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "\n",
    "# Suppose df is your DataFrame with 'text' and 'label' columns\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer() # You can also use CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Define your target variable\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"F1 Score:\", f1_score(y_test, predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'Film çox yaxşı idi. Çox xoşuma gəldi.'\n",
    "text2 = 'Film çox pis idi. Çox xoşuma gəlmədi.'\n",
    "text3 = 'Indiye qeder izlediyim en möhtəşəm film idi.'\n",
    "text4 = 'Yusif çox pis adam idi. Çox xoşuma gəlmədi.'\n",
    "text5 = 'Filmi izləmək istəmirəm. Çox pis idi.'\n",
    "text6 = 'Filmi bəyəndim, baxmağa dəyər.'\n",
    "text7 = 'Filmi bəyənmədim izləməyi tövsiyyə etmirəm.'\n",
    "text = \"Film çox əyləncəli idi.\"\n",
    "nb.predict(vectorizer.transform([text1, text2, text3, text4, text5, text6, text7, text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probs = defaultdict(float)\n",
    "        self.word_cond_probs = defaultdict(lambda: defaultdict(float))\n",
    "        self.vocab = set()\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        class_counts = y_train.value_counts().to_dict()\n",
    "        total_docs = len(y_train)\n",
    "        for c in class_counts:\n",
    "            self.class_probs[c] = np.log(class_counts[c] / total_docs)\n",
    "\n",
    "        word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        word_totals = defaultdict(int)\n",
    "        for text, c in zip(X_train, y_train):\n",
    "            for word in text.split():\n",
    "                self.vocab.add(word)\n",
    "                word_counts[c][word] += 1\n",
    "                word_totals[c] += 1\n",
    "\n",
    "        for c in class_counts:\n",
    "            for word in self.vocab:\n",
    "                self.word_cond_probs[c][word] = np.log(\n",
    "                    (word_counts[c][word] + 1) / (word_totals[c] + len(self.vocab))\n",
    "                )\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for text in X_test:\n",
    "            class_scores = {}\n",
    "            for c in self.class_probs:\n",
    "                score = self.class_probs[c]\n",
    "                for word in text.split():\n",
    "                    if word in self.vocab:\n",
    "                        score += self.word_cond_probs[c][word]\n",
    "                class_scores[c] = score\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        return predictions\n",
    "\n",
    "# Vectorize the text data manually or use the text as is for our simple implementation\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize, train, and predict using our Naive Bayes classifier\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer() # You can also use CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Define your target variable\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polygraf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
